{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# HackOnAzure Analysis:"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Importing Libraries:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom geopy.geocoders import Nominatim\nfrom pandas.io.json import json_normalize\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport scipy as sp\nfrom scipy.optimize import curve_fit\nfrom sklearn.cluster import KMeans \nfrom sklearn.datasets.samples_generator import make_blobs \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import silhouette_score,silhouette_samples\nimport folium\nimport os\nimport requests\nimport json\nimport matplotlib.pyplot as plt\nimport plotly.express as ex\nimport plotly.graph_objs as go\nimport dash\nimport dash_core_components as dcc\nimport dash_html_components as html\nfrom dash.dependencies import Input,Output,State\nimport os\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\")\n",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Load Dataset:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Load Data\n\ndf_ox = pd.read_parquet(\"https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/covid_policy_tracker/latest/covid_policy_tracker.parquet\")\ndf_ox.rename(columns = {'countryname':'Country/Region','date':'Date'},inplace=True)\ndf_ox['Date'] = pd.to_datetime(df_ox['Date'])\ndf_ox.rename(index = {'United States':'US'},inplace=True)\n\n\n# URL of the raw dataset provided by John Hopkins University\nurl_cases = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\nurl_deaths = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\nurl_recovered = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n\n# Importing CSV files from John Hopkins Github Dataset\ndf_cases = pd.read_csv(url_cases)                \ndf_deaths = pd.read_csv(url_deaths)                      \ndf_recovered = pd.read_csv(url_recovered)\n#print(df_cases.head())\n\ndates = df_cases.columns[4:]\n\ndf_cases_melt = df_cases.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n    value_vars=dates, \n    var_name='Date', \n    value_name='Confirmed')\n\ndf_deaths_melt = df_deaths.melt(\n    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n    value_vars=dates, \n    var_name='Date', \n    value_name='Deaths'\n)\ndf_recovered_melt = df_recovered.melt(\n    id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], \n    value_vars=dates, \n    var_name='Date', \n    value_name='Recovered'\n)\n\n# Merging all three csv files\ndf_data = pd.DataFrame()\n\ndf_data = df_cases_melt.merge(\n  right=df_deaths_melt, \n  how='left',\n  on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long']\n)\n\ndf_data = df_data.merge(\n  right=df_recovered_melt, \n  how='left',\n  on=['Province/State', 'Country/Region', 'Date', 'Lat', 'Long']\n)\n\n\n# Converting the column Date as a DateTime object\ndf_data['Date'] = pd.to_datetime(df_data['Date'])\n# Check for any missing values\n#print(df_data.isna().sum())\n# Replacing any missing values in Recovered column as 0 as it is the only possible explanation to it\ndf_data['Recovered'] = df_data['Recovered'].fillna(0)\n# Replacing missing values in State column as some countries do not update the statewise data\ndf_data['Province/State'] = df_data['Province/State'].fillna(df_data['Country/Region'])\n# Re-check missing values :\n#print(df_data.isna().sum())\n\n# Remoing the Ships data from the table as this project is focussed on a country level dataset\nfilter_1 = df_data['Country/Region'].str.contains('MS Zaandam')\nfilter_2 = df_data['Country/Region'].str.contains('Diamond Princess')\nfilter_3 = df_data['Province/State'].str.contains('Diamond Princess')\nfilter_4 = df_data['Province/State'].str.contains('Grand Princess')\n\ndf_data = df_data[~(filter_1 | filter_2 | filter_3 | filter_4)]\n\n#print(df_data)\n\n# Active Case = confirmed - (deaths + recovered)\ndf_data['Active'] = df_data['Confirmed'] - (df_data['Deaths'] + df_data['Recovered'])\n#print(df_data)\n\n# We dont need State data for country-wise analysis. \n# Removing the Latitude and Longitude columns as well because for the countries with specified data columns, Lat and Long data are different.\n# While plotting in folium, we will definitely need that data, but I will be using geopy package to get that data.\ndf = pd.DataFrame()\ndf = df_data.groupby(['Date', 'Country/Region'])['Confirmed', 'Deaths', 'Recovered', 'Active'].sum().reset_index()\n#print(df)\n\n\n# Also including Daily stats in df for better visualization and understanding in the later steps such as Data exploration and Visualization\ndf_temp = df.groupby(['Country/Region', 'Date', ])['Confirmed', 'Deaths', 'Recovered']\ndf_temp = df_temp.sum().diff().reset_index()\ndf_new = df_temp['Country/Region'] != df_temp['Country/Region'].shift(1)\ndf_temp.loc[df_new, 'Confirmed'] = np.nan\ndf_temp.loc[df_new, 'Deaths'] = np.nan\ndf_temp.loc[df_new, 'Recovered'] = np.nan\n# renaming columns\ndf_temp.columns = ['Country/Region', 'Date', 'New_Cases', 'New_Deaths', 'New_Recovered']\n# merging new values\ndf = pd.merge(df, df_temp, on=['Country/Region', 'Date'])\n# filling na with 0\ndf = df.fillna(0)\n# fixing data types\ncols = ['New_Cases', 'New_Deaths', 'New_Recovered']\ndf[cols] = df[cols].astype('int')\ndf['New_Cases'] = df['New_Cases'].apply(lambda x: 0 if x<0 else x)\n\n\n# Worldometer Data taken from OWID : \n\ndf_owid = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv',parse_dates = True)\nfilt_d = df_owid['location'].isin(['World','International'])\ndf_owid.drop(df_owid.loc[filt_d].index,axis=0,inplace=True)\ndf_owid['combined_smokers'] = df_owid['female_smokers'] + df_owid['male_smokers']\n\ndf_owid.rename(columns = {'location':'Country/Region','date':'Date'},inplace=True)\ndf_owid.set_index('Country/Region',inplace=True)\ndf_owid.rename(index = {'United States':'US'},inplace=True)\ndf_owid['Date'] = pd.to_datetime(df_owid['Date'])\ndf_owid.reset_index()\n\ndf_owid.drop(columns=['iso_code', 'total_cases', 'new_cases',\n       'total_deaths', 'new_deaths', 'total_cases_per_million',\n       'new_cases_per_million', 'total_deaths_per_million',\n       'new_deaths_per_million'],axis=1,inplace=True)\n\ndfs=df.copy()\ndfs = dfs.merge(right=df_owid, how='left', on=['Country/Region','Date'])\ndfs.fillna(0)\ndf1 = dfs\ndf1 = df1.merge(right=df_ox,how='left',on=['Country/Region','Date'])\ndf=df1\ndf.isna().sum()\ndf.fillna(0)\ndf['Date'] = pd.to_datetime(df['Date'])\n#df.head()\nprint()",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "color_code = {'Confirmed':'blue','Deaths':'red','Recovered':'green',\n              'New_Cases':'blue','New_Deaths':'red','New_Recovered':'green'}\n\nexternal_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n\n\n# Initializing Dash >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\napp = dash.Dash('Covid_19_Dashboard',external_stylesheets=external_stylesheets)\ncolors = {'background': '#111111','text': '#7FDBFF'}\ncolors = {'background': '#111111','text': '#7FDBFF'}\nmarkdown_text = 'Contact: priteshjha27@gmail.com'\n\n",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def sigmoid(x, a, b, c):\n    return a / (1 + np.exp(-b * (x - c))) + 1",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Web App Layout:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Layout - Tabs >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\napp.layout = html.Div([\n    html.H3(children='COVID-19 Tracker',style = {'textAlign':'center'}),\n    html.Div(children=markdown_text,style = {'textAlign':'right'}),\n    dcc.Tabs(id=\"tabs\", value='tab-1', children=[\n        dcc.Tab(label='World Statistics', value='tab-1'),\n        dcc.Tab(label='India - Predictive Model', value='tab-2'),\n    ]),\n    html.Div(id='tabs-content')\n])\n\n\n\n",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Tabs output >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\n@app.callback(Output('tabs-content', 'children'),\n              [Input('tabs', 'value')])\n\n\n# World Tab >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\ndef render_content(tab):\n    if tab == 'tab-1':\n        return html.Div([\n            dcc.Input(\n                id='input_text',\n                placeholder='Enter the Country Name: ',\n                type='text',\n                value='India'\n                ),\n                html.Button('Submit', id='button'),\n\n            dcc.Graph(\n                id = 'Stats'\n                )\n            ],\n            style = {'width':'500'})\n\n\n# India Daily Stats Tab >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>    \n        \n    \n    elif(tab == 'tab-2'):\n        return html.Div([\n            dcc.RadioItems(\n                id='radio',\n                options=[\n                    {'label': 'Predict Confirmed Cases', 'value': 'Confirmed'},\n                    {'label': 'Predict Death Count', 'value': 'Deaths'}\n                ],\n                value='Confirmed',\n                labelStyle={'display': 'inline-block'}\n                ),\n            dcc.Graph(\n                id = 'test_graph_radio'\n                )],style={'padding': '0px 10px 10px 10px'})\n\n# Else >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>        \n\n    else:\n        pass\n#app.css.append_css({'external_url': 'https://codepen.io/chriddyp/pen/bWLwgP.css'})\n\n\n",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Web app Callbacks:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# World Tab Callback >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\n@app.callback(Output('Stats', 'figure'), \n              [Input('button', 'n_clicks')],\n              [State('input_text', 'value')])\ndef update_graph(click,name):\n    Daily = {'C':'New_Cases','D':'New_Deaths','R':'New_Recovered'}\n    Total = {'C':'Confirmed','D':'Deaths','R':'Recovered'}\n    X = Total   \n    c = str(name)\n    filt_c = df['Country/Region']==c\n    filt_C = df['Confirmed'] > 0\n    dfc = df.loc[filt_c & filt_C]\n\n\n    fig = make_subplots(\n        rows=2, cols=2,\n        column_widths=[0.5, 0.5],\n        row_heights=[0.5, 0.5],\n        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n               [ {\"type\": \"bar\"} , {\"type\": \"bar\"}]])\n\n\n    fig.add_trace(go.Bar(x = dfc['Date'],y=dfc[X['C']]), row=1,col=1)\n\n\n    fig.add_trace(go.Bar(x = dfc['Date'],y=dfc[X['C']]), row=1,col=2)\n\n    fig.add_trace(go.Bar(x = dfc['Date'],y=dfc[X['D']]), row=2,col=1)\n\n    fig.add_trace(go.Bar(x = dfc['Date'],y=dfc[X['R']]), row=2,col=2)\n\n    fig.update_layout(\n        template=\"plotly_dark\",\n        margin=dict(r=10, t=25, b=40, l=60),\n        annotations=[\n            dict(\n                text=\"Source: NOAA\",\n                showarrow=False,\n                xref=\"paper\",\n                yref=\"paper\",\n                x=0,\n                y=0)\n        ]\n    )   \n  \n    return fig\n",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# India Stats Tab Callback >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\n@app.callback(Output('test_graph_radio', 'figure'), [Input('radio', 'value')])\ndef update_case(case_type):\n    Country_Train = 'India'\n\n    try:\n        df['Country/Region'].str.contains(Country_Train)\n        pass\n        #print('Found Data!')\n    except ValueError:\n        print('Invalid Country Name')\n\n\n    filter_5 = df['Country/Region']==str(Country_Train)\n    filter_6 = df[case_type]>0\n    # Requested Country DataFrame :\n    dfg = df.loc[filter_5 & filter_6]\n    dfg = dfg.reset_index()\n    dfg.drop(columns=['index'],inplace=True)\n    #print(df1.dtypes)\n    dfg['Day']=dfg.index + 1\n    #dfg.tail(2)\n\n    # Train_Test_Split:\n\n    train_x = dfg['Day']\n    train_y = dfg[case_type]\n\n    a = dfg[case_type].max()\n    b = 0.3\n    c = 100\n    p0 = (a, b, c)\n\n    popt, pcov = sp.optimize.curve_fit(sigmoid,  train_x,  train_y,  p0=p0 )\n\n    #x = range(1,dfg.shape[0] + int(popt[2]))\n    #y_fit = sigmoid(x, *popt)\n    x = train_x\n    model_y = sigmoid(train_x,*popt)\n\n    df_model = pd.DataFrame()\n    df_model['x'] = x\n    df_model['y'] = model_y.astype(int)\n\n    popt[0]=1.10*popt[0]\n    popt[1]=1.2*popt[1]\n    #print(\"Optimized a (the maximum number of confirmed cases): \" + str(int(popt[0])))\n    #print(\"Optimized b (growth rate): \" + str(float(popt[1])))\n    #print(\"Optimized c (the day of the inflexion): \" + str(int(popt[2])) + \"\")\n\n\n    p_df = pd.DataFrame()\n    d = train_x.max()\n    days = []\n    for x in range(d+1,d+30):\n        days.append(x)\n\n    p_df['Day'] = pd.Series(data=days)\n\n    test_x = p_df['Day']\n    y_predict_India = sigmoid(test_x, *popt)\n    p_df[case_type] = pd.Series(data=y_predict_India)\n    t_df = dfg[['Day',case_type]]\n\n    frames=[t_df,p_df]\n    prediction = pd.concat(frames,ignore_index=True)\n    prediction[case_type]\n\n    fig = go.Figure()\n\n    Confirmed_Cases = fig.add_trace(go.Scatter(x = t_df['Day'], y = t_df[case_type],mode = 'lines+markers',name = case_type))\n    Predicted_Cases = fig.add_trace(go.Scatter(x = p_df['Day'], y = p_df[case_type],mode = 'lines+markers', name='Predicted'))\n\n    #fig.show()\n    fig_prediction = fig\n    \n    return fig_prediction\n\n",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Run Local Server:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Run_Server >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n\nif __name__ == '__main__':\n    app.run_server()\n",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Dash is running on http://127.0.0.1:8050/\n\n Warning: This is a development server. Do not use app.run_server\n in production, use a production WSGI server like gunicorn instead.\n\n * Serving Flask app \"Covid_19_Dashboard\" (lazy loading)\n * Environment: production\n   WARNING: This is a development server. Do not use it in a production deployment.\n   Use a production WSGI server instead.\n * Debug mode: off\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}